{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47455b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from string import punctuation\n",
    "import re\n",
    "import spacy\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f7bb888",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>EssayTopic</th>\n",
       "      <th>EssayBody</th>\n",
       "      <th>ParagraphCount</th>\n",
       "      <th>WordCount</th>\n",
       "      <th>EssayScore</th>\n",
       "      <th>CC_Score</th>\n",
       "      <th>LR_Score</th>\n",
       "      <th>GRA_Score</th>\n",
       "      <th>TA_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Increasing the price of petrol is the best way...</td>\n",
       "      <td>Over the last century, our cities faced unprec...</td>\n",
       "      <td>4</td>\n",
       "      <td>350</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>5.5</td>\n",
       "      <td>6.5</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Fatherhood ought to be emphasized as much as m...</td>\n",
       "      <td>According to some people, the role of a father...</td>\n",
       "      <td>4</td>\n",
       "      <td>419</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>5.5</td>\n",
       "      <td>6.5</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Best way to reduce the number of crime among y...</td>\n",
       "      <td>Thesedays, number of crime commit by the young...</td>\n",
       "      <td>3</td>\n",
       "      <td>197</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Some people believe that it is good to share a...</td>\n",
       "      <td>Some people believe that sharing details of re...</td>\n",
       "      <td>4</td>\n",
       "      <td>281</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>5.5</td>\n",
       "      <td>6.5</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Some people believe that teaching children at ...</td>\n",
       "      <td>People these days have contradictory opinion r...</td>\n",
       "      <td>12</td>\n",
       "      <td>410</td>\n",
       "      <td>5.5</td>\n",
       "      <td>5.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                         EssayTopic  \\\n",
       "0   1  Increasing the price of petrol is the best way...   \n",
       "1   2  Fatherhood ought to be emphasized as much as m...   \n",
       "2   3  Best way to reduce the number of crime among y...   \n",
       "3   4  Some people believe that it is good to share a...   \n",
       "4   5  Some people believe that teaching children at ...   \n",
       "\n",
       "                                           EssayBody  ParagraphCount  \\\n",
       "0  Over the last century, our cities faced unprec...               4   \n",
       "1  According to some people, the role of a father...               4   \n",
       "2  Thesedays, number of crime commit by the young...               3   \n",
       "3  Some people believe that sharing details of re...               4   \n",
       "4  People these days have contradictory opinion r...              12   \n",
       "\n",
       "   WordCount  EssayScore  CC_Score  LR_Score  GRA_Score  TA_Score  \n",
       "0        350         6.0       5.5       5.5        6.5       6.5  \n",
       "1        419         6.0       5.5       5.5        6.5       7.0  \n",
       "2        197         5.0       5.5       5.0        6.5       5.0  \n",
       "3        281         6.0       6.5       5.5        6.5       6.0  \n",
       "4        410         5.5       5.5       5.0        5.5       5.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "essays = pd.read_csv('essay_dataset_new_full.csv', encoding = \"utf-8\")\n",
    "essays.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94e1f02c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24254, 10)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "essays.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9c0251b",
   "metadata": {},
   "outputs": [],
   "source": [
    "essays['EssayTopic'] = essays['EssayTopic'].apply(lambda x: x.encode('ascii', 'ignore').\\\n",
    "                                          strip().decode())\n",
    "\n",
    "essays['EssayBody'] = essays['EssayBody'].apply(lambda x: x.encode('ascii', 'ignore').\\\n",
    "                                          strip().decode())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7e307d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of null values in each column:\n",
      " \n",
      "ID                0\n",
      "EssayTopic        0\n",
      "EssayBody         0\n",
      "ParagraphCount    0\n",
      "WordCount         0\n",
      "EssayScore        0\n",
      "CC_Score          0\n",
      "LR_Score          0\n",
      "GRA_Score         0\n",
      "TA_Score          0\n",
      "dtype: int64\n",
      "\n",
      "Data Type of each column:\n",
      " \n",
      "ID                  int64\n",
      "EssayTopic         object\n",
      "EssayBody          object\n",
      "ParagraphCount      int64\n",
      "WordCount           int64\n",
      "EssayScore        float64\n",
      "CC_Score          float64\n",
      "LR_Score          float64\n",
      "GRA_Score         float64\n",
      "TA_Score          float64\n",
      "dtype: object \n",
      "\n"
     ]
    }
   ],
   "source": [
    "isnull = essays.isnull().sum()\n",
    "dtype = essays.dtypes\n",
    "print('Number of null values in each column:\\n \\n{}\\n'.format(isnull))\n",
    "print('Data Type of each column:\\n \\n{} \\n'.format(dtype))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ba76c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "nlp.add_pipe(\"merge_entities\")\n",
    "def ner_tag(text):\n",
    "    doc = nlp(text)\n",
    "    new_text = (\" \".join([t.text if not t.ent_type_ else \"@\"+t.ent_type_ for t in doc])).strip()\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f833e49",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'essays' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m essays[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEssayBody\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43messays\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEssayBody\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmap(ner_tag)\n\u001b[1;32m      2\u001b[0m essays\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124messay_dataset_with_ner.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'essays' is not defined"
     ]
    }
   ],
   "source": [
    "essays['EssayBody'] = essays['EssayBody'].map(ner_tag)\n",
    "essays.to_csv('essay_dataset_with_ner.csv')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9d16eaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>EssayBody</th>\n",
       "      <th>ParagraphCount</th>\n",
       "      <th>WordCount</th>\n",
       "      <th>EssayScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32113</td>\n",
       "      <td>A balanced professional and personal life is t...</td>\n",
       "      <td>4</td>\n",
       "      <td>290</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22939</td>\n",
       "      <td>A better climate is required for the good life...</td>\n",
       "      <td>4</td>\n",
       "      <td>316</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20092</td>\n",
       "      <td>A big boom in the automobile industry has laun...</td>\n",
       "      <td>4</td>\n",
       "      <td>315</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24691</td>\n",
       "      <td>A big deal of people agree that social network...</td>\n",
       "      <td>5</td>\n",
       "      <td>287</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30157</td>\n",
       "      <td>A big number of people in our country still be...</td>\n",
       "      <td>4</td>\n",
       "      <td>300</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID                                          EssayBody  ParagraphCount  \\\n",
       "0  32113  A balanced professional and personal life is t...               4   \n",
       "1  22939  A better climate is required for the good life...               4   \n",
       "2  20092  A big boom in the automobile industry has laun...               4   \n",
       "3  24691  A big deal of people agree that social network...               5   \n",
       "4  30157  A big number of people in our country still be...               4   \n",
       "\n",
       "   WordCount  EssayScore  \n",
       "0        290         6.0  \n",
       "1        316         7.5  \n",
       "2        315         7.0  \n",
       "3        287         7.5  \n",
       "4        300         8.5  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_essays = pd.read_csv('essay_dataset_with_ner.csv')\n",
    "clean_essays.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ecd002",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_topic(text):\n",
    "    text = text.lower()  # Lowercase text\n",
    "    text = re.sub(f\"[{re.escape(punctuation)}]\", \"\", text)  # Remove punctuation\n",
    "    text = \" \".join(text.split())  # Remove extra spaces, tabs, and new lines\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a10c1d2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "clean_essays['EssayScore'].value_counts().sort_index().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d333a56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "essays['EssayTopic'] = essays['EssayTopic'].map(clean_topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0648bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"def convert_to_category(score):\n",
    "    if score == 5.0:\n",
    "        return str(0)\n",
    "    elif score == 5.5:\n",
    "        return str(1)\n",
    "    elif score == 6.0:\n",
    "        return str(1)\n",
    "    elif score == 6.5:\n",
    "        return str(1)\n",
    "    elif score == 7.0:\n",
    "        return str(1)\n",
    "    elif score == 7.5:\n",
    "        return str(1)\n",
    "    elif score == 8.5:\n",
    "        return str(1)\n",
    "    else:\n",
    "        return str(9)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5f96ec1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>EssayBody</th>\n",
       "      <th>ParagraphCount</th>\n",
       "      <th>WordCount</th>\n",
       "      <th>EssayScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32113</td>\n",
       "      <td>A balanced professional and personal life is t...</td>\n",
       "      <td>4</td>\n",
       "      <td>290</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22939</td>\n",
       "      <td>A better climate is required for the good life...</td>\n",
       "      <td>4</td>\n",
       "      <td>316</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20092</td>\n",
       "      <td>A big boom in the automobile industry has laun...</td>\n",
       "      <td>4</td>\n",
       "      <td>315</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24691</td>\n",
       "      <td>A big deal of people agree that social network...</td>\n",
       "      <td>5</td>\n",
       "      <td>287</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30157</td>\n",
       "      <td>A big number of people in our country still be...</td>\n",
       "      <td>4</td>\n",
       "      <td>300</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID                                          EssayBody  ParagraphCount  \\\n",
       "0  32113  A balanced professional and personal life is t...               4   \n",
       "1  22939  A better climate is required for the good life...               4   \n",
       "2  20092  A big boom in the automobile industry has laun...               4   \n",
       "3  24691  A big deal of people agree that social network...               5   \n",
       "4  30157  A big number of people in our country still be...               4   \n",
       "\n",
       "   WordCount  EssayScore  \n",
       "0        290           2  \n",
       "1        316           5  \n",
       "2        315           4  \n",
       "3        287           5  \n",
       "4        300           7  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_essays['EssayScore'] = clean_essays.EssayScore.astype(\"category\").cat.codes\n",
    "clean_essays.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d0c00a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                 int64\n",
       "EssayBody         object\n",
       "ParagraphCount     int64\n",
       "WordCount          int64\n",
       "EssayScore          int8\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_essays.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095ba519",
   "metadata": {},
   "source": [
    "_______"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4bfa868",
   "metadata": {},
   "source": [
    "_________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7b82340",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = clean_essays[['EssayBody']].copy()\n",
    "y = clean_essays[['EssayScore']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c86a044f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/ekrembakay/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/ekrembakay/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f1540f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def essay_to_wordlist(sentence):\n",
    "    \"\"\"Remove the tagged labels and word tokenize the sentence.\"\"\"\n",
    "    words = nltk.word_tokenize(sentence)\n",
    "    return words\n",
    "\n",
    "def essay_to_sentences(essay):\n",
    "    \"\"\"Sentence tokenize the essay and call essay_to_wordlist() for word tokenization.\"\"\"\n",
    "    raw_sentences = nltk.sent_tokenize(essay.strip())\n",
    "    sentences = []\n",
    "    for raw_sentence in raw_sentences:\n",
    "        if len(raw_sentence) > 0:\n",
    "            sentences.append(essay_to_wordlist(raw_sentence))\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "776beb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def makeFeatureVec(words, model, num_features):\n",
    "    \"\"\"Make Feature Vector from the words list of an Essay.\"\"\"\n",
    "    featureVec = np.zeros((num_features,),dtype=\"float32\")\n",
    "    num_words = 0.\n",
    "    index2word_set = set(model.wv.index_to_key)\n",
    "    for word in words:\n",
    "        if word in index2word_set:\n",
    "            num_words += 1\n",
    "            featureVec = np.add(featureVec,model.wv[word])        \n",
    "    featureVec = np.divide(featureVec,num_words)\n",
    "    return featureVec\n",
    "\n",
    "def getAvgFeatureVecs(essays, model, num_features):\n",
    "    \"\"\"Main function to generate the word vectors for word2vec model.\"\"\"\n",
    "    counter = 0\n",
    "    essayFeatureVecs = np.zeros((len(essays),num_features),dtype=\"float32\")\n",
    "    for essay in essays:\n",
    "        essayFeatureVecs[counter] = makeFeatureVec(essay, model, num_features)\n",
    "        counter = counter + 1\n",
    "    return essayFeatureVecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7fee99ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Embedding, LSTM, Dense, Dropout, Lambda, Flatten\n",
    "from keras.models import Sequential, load_model, model_from_config\n",
    "import keras.backend as K\n",
    "\n",
    "def get_model():\n",
    "    \"\"\"Define the model.\"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(300, dropout=0.4, recurrent_dropout=0.4, input_shape=[1, 300], return_sequences=True))\n",
    "    model.add(LSTM(64, recurrent_dropout=0.4))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='relu'))\n",
    "\n",
    "    model.compile(loss='mean_squared_error', optimizer='rmsprop', metrics=['mae'])\n",
    "    model.summary()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba16ec1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from constants import GLOVE_DIR\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout, Lambda, Flatten\n",
    "from keras.models import Sequential\n",
    "import keras.backend as K\n",
    "from utils import tokenizer, load_embedding_matrix\n",
    "\n",
    "def get_model(embedding_dimension, essay_length):\n",
    "    vocabulary_size = len(tokenizer.word_index) + 1\n",
    "    embedding_matrix = load_embedding_matrix(glove_directory=GLOVE_DIR, embedding_dimension=embedding_dimension)\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Embedding(vocabulary_size, embedding_dimension, weights=[embedding_matrix], input_length=essay_length, trainable=False, mask_zero=False))\n",
    "    model.add(LSTM(128, dropout=0.4, recurrent_dropout=0.4))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Lambda(lambda x: K.mean(x, axis=1, keepdims=True)))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='mean_squared_error', optimizer='rmsprop', metrics=['mae'])\n",
    "    model.summary()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "feb2e6e0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------Fold 1--------\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "essay_to_sentences() got an unexpected keyword argument 'remove_stopwords'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m sentences \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m essay \u001b[38;5;129;01min\u001b[39;00m train_essays:\n\u001b[1;32m     20\u001b[0m         \u001b[38;5;66;03m# Obtaining all sentences from the training essays.\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m         sentences \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43messay_to_sentences\u001b[49m\u001b[43m(\u001b[49m\u001b[43messay\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mremove_stopwords\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Initializing variables for word2vec model.\u001b[39;00m\n\u001b[1;32m     24\u001b[0m num_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m300\u001b[39m \n",
      "\u001b[0;31mTypeError\u001b[0m: essay_to_sentences() got an unexpected keyword argument 'remove_stopwords'"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "cv = KFold(5, shuffle=True)\n",
    "results = []\n",
    "y_pred_list = []\n",
    "\n",
    "count = 1\n",
    "for traincv, testcv in cv.split(X):\n",
    "    print(\"\\n--------Fold {}--------\\n\".format(count))\n",
    "    X_test, X_train, y_test, y_train = X.iloc[testcv], X.iloc[traincv], y.iloc[testcv], y.iloc[traincv]\n",
    "    \n",
    "    train_essays = X_train['EssayBody']\n",
    "    test_essays = X_test['EssayBody']\n",
    "    \n",
    "    sentences = []\n",
    "    \n",
    "    for essay in train_essays:\n",
    "            # Obtaining all sentences from the training essays.\n",
    "            sentences += essay_to_sentences(essay, remove_stopwords = True)\n",
    "            \n",
    "    # Initializing variables for word2vec model.\n",
    "    num_features = 300 \n",
    "    min_word_count = 40\n",
    "    num_workers = 4\n",
    "    context = 10\n",
    "    downsampling = 1e-3\n",
    "\n",
    "    print(\"Training Word2Vec Model...\")\n",
    "    model = Word2Vec(sentences, workers=num_workers, vector_size=num_features, min_count = min_word_count, window = context, sample = downsampling)\n",
    "\n",
    "    model.init_sims(replace=True)\n",
    "    model.wv.save_word2vec_format('word2vecmodel.bin', binary=True)\n",
    "\n",
    "    clean_train_essays = []\n",
    "    \n",
    "    # Generate training and testing data word vectors.\n",
    "    for essay_v in train_essays:\n",
    "        clean_train_essays.append(essay_to_wordlist(essay_v, remove_stopwords=True))\n",
    "    trainDataVecs = getAvgFeatureVecs(clean_train_essays, model, num_features)\n",
    "    \n",
    "    clean_test_essays = []\n",
    "    for essay_v in test_essays:\n",
    "        clean_test_essays.append(essay_to_wordlist( essay_v, remove_stopwords=True ))\n",
    "    testDataVecs = getAvgFeatureVecs(clean_test_essays, model, num_features )\n",
    "    \n",
    "    trainDataVecs = np.array(trainDataVecs)\n",
    "    testDataVecs = np.array(testDataVecs)\n",
    "    # Reshaping train and test vectors to 3 dimensions. (1 represnts one timestep)\n",
    "    trainDataVecs = np.reshape(trainDataVecs, (trainDataVecs.shape[0], 1, trainDataVecs.shape[1]))\n",
    "    testDataVecs = np.reshape(testDataVecs, (testDataVecs.shape[0], 1, testDataVecs.shape[1]))\n",
    "    \n",
    "    lstm_model = get_model()\n",
    "    lstm_model.fit(trainDataVecs, y_train, batch_size=64, epochs=50)\n",
    "    #lstm_model.load_weights('./model_weights/final_lstm.h5')\n",
    "    y_pred = lstm_model.predict(testDataVecs)\n",
    "    \n",
    "    # Round y_pred to the nearest integer.\n",
    "    y_pred2 = np.around(y_pred)\n",
    "    y_test = np.around(y_test)\n",
    "    \n",
    "    # Save any one of the 8 models.\n",
    "    if count == 5:\n",
    "         lstm_model.save('./model_weights/final_lstm.h5')\n",
    "    \n",
    "    # Evaluate the model on the evaluation metric. \"Quadratic mean averaged Kappa\"\n",
    "    result = cohen_kappa_score(y_test.values,y_pred2,weights='quadratic')\n",
    "    print(\"Kappa Score: {}\".format(result))\n",
    "    results.append(result)\n",
    "    \n",
    "    count += 1\n",
    "    break"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bc259a1f",
   "metadata": {},
   "source": [
    "y_test2 = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0bb7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42204f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d471909c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777807b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = np.around(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb5d94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.around(y_pred - 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8619fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test2 = y_test.values\n",
    "y_test2 = np.around(y_test2, decimals = 1)\n",
    "y_test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497338f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
