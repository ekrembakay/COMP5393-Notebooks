{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6ca8ef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in /home/ekrem/anaconda3/lib/python3.9/site-packages (4.11.1)\r\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/ekrem/anaconda3/lib/python3.9/site-packages (from beautifulsoup4) (2.3.1)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b4f3f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d121a2a",
   "metadata": {},
   "source": [
    "def get_links(page_number):\n",
    "    URL = \"https://ielts69.com/essay/p/\" + str(page_number)\n",
    "    page = requests.get(URL)\n",
    "    soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "    results = soup.find(class_=\"similar-post-list\")\n",
    "    link_elements = results.find_all(\"a\", href=True)\n",
    "    \n",
    "    links = []\n",
    "    \n",
    "    for link_element in link_elements:\n",
    "        link_url = link_element[\"href\"]\n",
    "        links.append(link_url)\n",
    "    \n",
    "    return links"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8178e0f4",
   "metadata": {},
   "source": [
    "all_links = []\n",
    "for i in range(1,2061):\n",
    "    links = get_links(i)\n",
    "    all_links.append(links)\n",
    "\n",
    "all_links\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae535ad4",
   "metadata": {},
   "source": [
    "list_of_links = np.asarray(all_links).ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d505fbe5",
   "metadata": {},
   "source": [
    "df = pd.DataFrame(list_of_links)\n",
    "df.to_csv(\"essay_links.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78e8142d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['/essay/increasing-the-price-of-petrol-is-the-best-way-to-solve-growing-traffic-and-pollution-problems-1',\n",
       "       '/essay/fatherhood-ought-to-be-emphasized-as-much-as-motherhood-1',\n",
       "       '/essay/as-computers-are-being-used-more-and-more-in-education-there-will-be-soon-no-role-for-teachers-in-the-classroom-1',\n",
       "       ...,\n",
       "       '/essay/tpo-22-do-you-agree-or-disagree-with-the-following-statement-1',\n",
       "       '/essay/tpo-20-do-you-agree-or-disagree-with-the-following-statement-2',\n",
       "       '/essay/tpo-19-do-you-agree-or-disagree-with-the-following-statement-3'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links = pd.read_csv(\"essay_links.csv\")\n",
    "list_of_links = links['0'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ec7267b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(page_url):\n",
    "    new_dict = {}\n",
    "\n",
    "    URL2 = 'https://ielts69.com' + str(page_url)\n",
    "    essay_page = requests.get(URL2)\n",
    "    soup2 = BeautifulSoup(essay_page.content, \"html.parser\")\n",
    "\n",
    "    essay_text = soup2.find(\"div\", id=\"editor\")\n",
    "    #text = results2.find_all()\n",
    "    \n",
    "    if essay_text != None:\n",
    "        for tag in essay_text.select('div.popup'):\n",
    "            tag.decompose()\n",
    "    \n",
    "        delimiter = '#'      \n",
    "\n",
    "        for line_break in essay_text.findAll('br'):      \n",
    "            line_break.replaceWith(delimiter)\n",
    "\n",
    "    paragraph_number = soup2.find(\"i\", id=\"totalParagraphs\")\n",
    "    word_count = soup2.find(\"i\", id=\"totalWords\")\n",
    "    essay_topic = soup2.find(\"h1\")\n",
    "    essay_score = soup2.find(\"div\", id=\"bandTotal\")\n",
    "\n",
    "    ccTotal = soup2.find(\"i\", id=\"ccTotal\")\n",
    "    lrTotal = soup2.find(\"i\", id=\"lrTotal\")\n",
    "    graTotal = soup2.find(\"i\", id=\"graTotal\")\n",
    "    taTotal = soup2.find(\"i\", id=\"taTotal\")\n",
    "\n",
    "    new_dict = {'EssayTopic': essay_topic.text, 'EssayBody': \"No text\" if essay_text == None else essay_text.text, \n",
    "            'ParagraphCount': int(paragraph_number.text), 'WordCount': int(word_count.text), \n",
    "            'EssayScore': float(essay_score.text), 'CC_Score': float(ccTotal.text), \n",
    "            'LR_Score': float(lrTotal.text), 'GRA_Score': float(graTotal.text), 'TA_Score': float(taTotal.text)}\n",
    "    \n",
    "    return new_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a8b3ed95",
   "metadata": {},
   "outputs": [],
   "source": [
    "Essay_Dataset = pd.DataFrame(columns=['EssayTopic', 'EssayBody', 'ParagraphCount', \n",
    "                                     'WordCount', 'EssayScore', 'CC_Score', 'LR_Score', \n",
    "                                     'GRA_Score', 'TA_Score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cfebc5ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%1 is compl11ete\n",
      "%2 is compl11ete\n",
      "%3 is compl11ete\n",
      "%4 is compl11ete\n",
      "%5 is compl11ete\n",
      "%6 is compl11ete\n",
      "%7 is compl11ete\n",
      "%8 is compl11ete\n",
      "%9 is compl11ete\n",
      "%10 is compl11ete\n",
      "%11 is compl11ete\n",
      "%12 is compl11ete\n",
      "%13 is compl11ete\n",
      "%14 is compl11ete\n",
      "%15 is compl11ete\n",
      "%16 is compl11ete\n",
      "%17 is compl11ete\n",
      "%18 is compl11ete\n",
      "%19 is compl11ete\n",
      "%20 is compl11ete\n",
      "%21 is compl11ete\n",
      "%22 is compl11ete\n",
      "%23 is compl11ete\n",
      "%24 is compl11ete\n",
      "%25 is compl11ete\n",
      "%26 is compl11ete\n",
      "%27 is compl11ete\n",
      "%28 is compl11ete\n",
      "%29 is compl11ete\n",
      "%30 is compl11ete\n",
      "%31 is compl11ete\n",
      "%32 is compl11ete\n",
      "%33 is compl11ete\n",
      "%34 is compl11ete\n",
      "%35 is compl11ete\n",
      "%36 is compl11ete\n",
      "%37 is compl11ete\n",
      "%38 is compl11ete\n",
      "%39 is compl11ete\n",
      "%40 is compl11ete\n",
      "%41 is compl11ete\n",
      "%42 is compl11ete\n",
      "%43 is compl11ete\n",
      "%44 is compl11ete\n",
      "%45 is compl11ete\n",
      "%46 is compl11ete\n",
      "%47 is compl11ete\n",
      "%48 is compl11ete\n",
      "%49 is compl11ete\n",
      "%50 is compl11ete\n",
      "%51 is compl11ete\n",
      "%52 is compl11ete\n",
      "%53 is compl11ete\n",
      "%54 is compl11ete\n",
      "%55 is compl11ete\n",
      "%56 is compl11ete\n",
      "%57 is compl11ete\n",
      "%58 is compl11ete\n",
      "%59 is compl11ete\n",
      "%60 is compl11ete\n",
      "%61 is compl11ete\n",
      "%62 is compl11ete\n",
      "%63 is compl11ete\n",
      "%64 is compl11ete\n",
      "%65 is compl11ete\n",
      "%66 is compl11ete\n",
      "%67 is compl11ete\n",
      "%68 is compl11ete\n",
      "%69 is compl11ete\n",
      "%70 is compl11ete\n",
      "%71 is compl11ete\n",
      "%72 is compl11ete\n",
      "%73 is compl11ete\n",
      "%74 is compl11ete\n",
      "%75 is compl11ete\n",
      "%76 is compl11ete\n",
      "%77 is compl11ete\n",
      "%78 is compl11ete\n",
      "%79 is compl11ete\n",
      "%80 is compl11ete\n",
      "%81 is compl11ete\n",
      "%82 is compl11ete\n",
      "%83 is compl11ete\n",
      "%84 is compl11ete\n",
      "%85 is compl11ete\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "complete = 0\n",
    "for index_number, url in enumerate(list_of_links[36090:]):\n",
    "    data = get_data(url)\n",
    "    new_row = pd.DataFrame(data, index=[index_number])\n",
    "    Essay_Dataset = pd.concat([Essay_Dataset, new_row])\n",
    "    \n",
    "    if ((index_number % 60) == 0) and (index_number != 0):\n",
    "        complete += 1\n",
    "        print(\"%{} is compl11ete\".format(complete))\n",
    "        \n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44191ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Essay_Dataset.to_csv(\"essay_dataset9.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9aa9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Essay_Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8c4d7b6b",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [43]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m essay_text\u001b[38;5;241m.\u001b[39mtext \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo text\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      2\u001b[0m essay_text\u001b[38;5;241m.\u001b[39mtext\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'text'"
     ]
    }
   ],
   "source": [
    "essay_text = \"No text\"\n",
    "essay_text.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d313da50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
